{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Variational_Autoencoder_for_Image_Embedding",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zl0l5l5utXnk_LHwzrwnabMpxL-FjjuG",
      "authorship_tag": "ABX9TyMh+8wsZaXeHXIBykjDNN7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjc16/Project_Notebooks/blob/master/Variational_Autoencoder_for_Image_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwbtUOa7uf98"
      },
      "source": [
        "# Variational Autoencoder for Image Embedding\n",
        "\n",
        "This notebook demonstrates development of a fast prototype for ranking similar images in an input training set. \n",
        "\n",
        "## Background: \n",
        "Variational autoencoders expand traditional autoencoders by using a trained Linear layer to shape the latent space in a traditional autoencoder to have normally distributed values. It does this by \n",
        "  - training the Linear layer by taking the KL-divergence between the transformed latent space and a $N (0,1)$ distribution (where $N$ is the normal distribution) and \n",
        "  - sampling the reconstructed images from the latent space (assuming a normal distribution) and using the sampled images to calculate the reconstruction loss\n",
        "\n",
        "## Novelties in notebook\n",
        "\n",
        "This notebook also adds a classification head that inputs the latent space and outputs logits for each class in the dataset. The idea here is to not only identify close images (in the latent space) but also return the probable classes.\n",
        "\n",
        "## References:\n",
        "\n",
        "The author utilized several third-party sources to create this notebook:\n",
        "\n",
        "- Data source: http://aws-proserve-data-science.s3.amazonaws.com/geological_similarity.zip \n",
        "\n",
        "- PyTorch Lightning Bolts: https://pytorch-lightning-bolts.readthedocs.io/\n",
        "\n",
        "If you wish to use any code from this notebook in your project, please contact the author: j j c 1 6 [at] y a h o o . c o m. The author makes no warranty, express or implied, about the suitability of this code for any project.\n",
        "\n",
        "We start by installing PyTorch Lighting Bolts (moved to end of notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMaCNH1T32tc"
      },
      "source": [
        "## Imports\n",
        "\n",
        "We need to import the needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysy4cjwBvAXR"
      },
      "source": [
        "import torch\n",
        "from pl_bolts.models.autoencoders import VAE\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "import pandas as pd\n",
        "\n",
        "device = 'cuda:0'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phHru24V37Vu"
      },
      "source": [
        "## Connect data storage location\n",
        "\n",
        "Now, we connect the data, show a sample image, print the max and min values, and display the shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "OVstqgNS254M",
        "outputId": "3a64a6a9-4188-484a-e812-1843b4036860"
      },
      "source": [
        "pth = '/content/drive/MyDrive/geo_sim/geological_similarity/andesite/01LQQ.jpg'\n",
        "with Image.open(pth,'r') as im:\n",
        "  data = np.asarray(im)\n",
        "imshow(data)\n",
        "print(f'Picture Min value: {np.min(data)}')\n",
        "print(f'Picture Max value: {np.max(data)}')\n",
        "print(f'Picture Shape: {data.shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Picture Min value: 63\n",
            "Picture Max value: 198\n",
            "Picture Shape: (28, 28, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP4DFYhl4WtJ"
      },
      "source": [
        "## Transforms\n",
        "\n",
        "We will be using a Resnet18 model for the image encoder and decoder. To do this, our images need to be at least size 32 x 32. Also, we need to normalize the images (using values explained in the Resnet18 documentation) and turn the outputs into tensors for model ingestion. The results of doing this are below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmO-34SE7iIK",
        "outputId": "00884519-9eb0-4513-b123-0e84fe851fd8"
      },
      "source": [
        "trans_norm = torchvision.transforms.Normalize((0.485, 0.456, 0.406), \n",
        "                                         (0.229, 0.224, 0.225))\n",
        "trans_resize = torchvision.transforms.Resize(size=(32,32))\n",
        "trans_ten = torchvision.transforms.ToTensor()\n",
        "# trans_un = torchvision.transforms.Lambda(lambda x: torch.unsqueeze(x,0))\n",
        "trans_comp = torchvision.transforms.Compose([trans_ten, trans_resize, trans_norm])\n",
        "out = trans_comp(data)\n",
        "print(out.shape)\n",
        "print(data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "(28, 28, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:114: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0iK9mlb4y9C"
      },
      "source": [
        "## Model:\n",
        "\n",
        "Now, we create a variational autoencoder model (VAE). We utilize PyTorch Lighting Bolts to skip writing boilerplate code and greatly accelerate our development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43TxLXeDulQq",
        "outputId": "99159466-2d56-43da-cdf2-a9a3e9546437"
      },
      "source": [
        "model = VAE(input_height=32)\n",
        "print(model)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (encoder): ResNetEncoder(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): EncoderBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): EncoderBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): EncoderBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): EncoderBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): EncoderBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): EncoderBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): EncoderBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): EncoderBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (decoder): ResNetDecoder(\n",
            "    (linear): Linear(in_features=256, out_features=8192, bias=True)\n",
            "    (layer1): Sequential(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Sequential(\n",
            "          (0): Interpolate()\n",
            "          (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (upsample): Sequential(\n",
            "          (0): Sequential(\n",
            "            (0): Interpolate()\n",
            "            (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Sequential(\n",
            "          (0): Interpolate()\n",
            "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (upsample): Sequential(\n",
            "          (0): Sequential(\n",
            "            (0): Interpolate()\n",
            "            (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Sequential(\n",
            "          (0): Interpolate()\n",
            "          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (upsample): Sequential(\n",
            "          (0): Sequential(\n",
            "            (0): Interpolate()\n",
            "            (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          )\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (upscale): Interpolate()\n",
            "    (upscale1): Interpolate()\n",
            "    (conv1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            "  (fc_mu): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc_var): Linear(in_features=512, out_features=256, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZNwfah55RBk"
      },
      "source": [
        "## Datasets and Dataloader:\n",
        "\n",
        "We now create PyTorch Datasets and DataLoaders for the training, validation, and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuGNMbDb-Jfl",
        "outputId": "a08e610c-804b-4f3d-d6e3-25a4a2aa82ee"
      },
      "source": [
        "ds = torchvision.datasets.ImageFolder('/content/drive/MyDrive/geo_sim/geological_similarity', transform=trans_comp)\n",
        "from math import floor\n",
        "tr_len = floor(0.8*len(ds))\n",
        "val_ln = floor(0.1*len(ds))\n",
        "tst_ln = len(ds) - tr_len - val_ln\n",
        "train_ds, val_ds, test_ds = torch.utils.data.random_split(ds, [tr_len, val_ln, tst_ln])\n",
        "print(len(train_ds), len(val_ds), len(test_ds))\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, num_workers=2)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=64, num_workers=2)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, num_workers=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23999 2999 3001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4-DSKT85k86"
      },
      "source": [
        "## Custom VAE Model\n",
        "\n",
        "The VAE model that is created by default doesn't have quite the features that we want. We also want to add a linear classification head to it to predict the classes of the encoded images. To do this, we create a custom model with a an extra linear layer and an overriden step function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVhjrZCZOqfl"
      },
      "source": [
        "class CustomVAE(VAE):\n",
        "  def __init__(self, *args, num_classes=6, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.classification_head = torch.nn.Linear(self.latent_dim, num_classes)\n",
        "\n",
        "  def step(self, batch, batch_idx, alpha=0.1):\n",
        "    loss, logs = super().step(batch, batch_idx)\n",
        "    enc = self.encoder(batch[0])\n",
        "    enc_mu = self.fc_mu(enc)\n",
        "    x_cl = self.classification_head(enc_mu)\n",
        "    labels = batch[1]\n",
        "    # print(labels.shape)\n",
        "    # print(x_cl.shape)\n",
        "    loss_class = alpha*torch.nn.CrossEntropyLoss()(x_cl, labels)\n",
        "    loss = loss + loss_class\n",
        "    # if batch_idx % 10 ==0:\n",
        "    #   print(batch_idx)\n",
        "    return loss, logs\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OROu9lkjJcCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704b643c-a02b-4853-f6fd-5343c8a1e285"
      },
      "source": [
        "cust_model = CustomVAE(input_height=32)\n",
        "# model = MyLightningModule\n",
        "cust_model.load_from_checkpoint('/content/drive/MyDrive/model.ckpt')\n",
        "#params = torch.load('/content/drive/MyDrive/lightning_logs/lightning_logs/version_0/checkpoints/hparams.yaml')\n",
        "# model=pl.LightningModule.load_from_checkpoint('/content/drive/MyDrive/lightning_logs/lightning_logs/version_0/checkpoints/vae_model.ckpt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomVAE(\n",
              "  (encoder): ResNetEncoder(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): EncoderBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): EncoderBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): EncoderBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): EncoderBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): EncoderBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): EncoderBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (decoder): ResNetDecoder(\n",
              "    (linear): Linear(in_features=256, out_features=8192, bias=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Sequential(\n",
              "          (0): Interpolate()\n",
              "          (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (upsample): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Interpolate()\n",
              "            (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Sequential(\n",
              "          (0): Interpolate()\n",
              "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (upsample): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Interpolate()\n",
              "            (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Sequential(\n",
              "          (0): Interpolate()\n",
              "          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (upsample): Sequential(\n",
              "          (0): Sequential(\n",
              "            (0): Interpolate()\n",
              "            (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): DecoderBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): DecoderBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (upscale): Interpolate()\n",
              "    (upscale1): Interpolate()\n",
              "    (conv1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (fc_mu): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc_var): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (classification_head): Linear(in_features=256, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceUhdMJW6L7S"
      },
      "source": [
        "## PyTorch Lighting Bolts Trainer\n",
        "\n",
        "Now, we create a trainer and use the .fit method to fit to our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POdMCCh1TGIP"
      },
      "source": [
        "# tr = pl.Trainer(max_epochs=20, gpus=1,progress_bar_refresh_rate=1, default_root_dir='/content/drive/MyDrive/lightning_logs/')\n",
        "# tr.fit(cust_model, train_dataloader=train_dl, val_dataloaders=val_dl)\n",
        "# tr.save_checkpoint('/content/drive/MyDrive/model.ckpt')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh4eqUiHmZzC"
      },
      "source": [
        "## Image embedding\n",
        "\n",
        "Once we are satisfied with the results of the model training, we can use the trained model to embed the images. The process of embedding can take a long time because we have to do several inferences through the model. However, these embeddings can be precomputed and stored in a file for later search.\n",
        "\n",
        "Below, we first get a list of files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YxqZACwbMwE",
        "outputId": "bc4c646c-cd55-4a74-9420-f6a900275f81"
      },
      "source": [
        "import os\n",
        "pth = '/content/drive/MyDrive/geo_sim/geological_similarity/'\n",
        "out = []\n",
        "for path, subdirs, files in os.walk(pth):\n",
        "    for name in files:\n",
        "      if name[0] != '.':\n",
        "        out.append(os.path.join(path, name))\n",
        "print(len(out))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCBNTMe380z9",
        "outputId": "83c2d154-64d3-44e3-9f0e-a6015324cd9c"
      },
      "source": [
        "# fl = out[20000]\n",
        "# img = Image.open(fl)\n",
        "# img = np.asarray(img)\n",
        "# # img = cust_model(trans_comp(img).unsqueeze(0))\n",
        "# enc = cust_model.encoder(trans_comp(img).unsqueeze(0))\n",
        "# enc = cust_model.fc_mu(enc).squeeze()\n",
        "# enc.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qXq_g6xnWQ4"
      },
      "source": [
        "Next, we embed the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jYcqqe8cY7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ff224f-3fdf-4d5c-92f7-f301b9c22ad4"
      },
      "source": [
        "# from PIL import Image\n",
        "# img_paths = []\n",
        "# img_emb_list = []\n",
        "# for ii, fl in enumerate(out):\n",
        "#   if ii % 100 == 0:\n",
        "#     print(f'Iter: {ii}')\n",
        "#     # print(enc.shape)\n",
        "#   img = Image.open(fl)\n",
        "#   img = np.asarray(img)\n",
        "#   # img = cust_model(trans_comp(img).unsqueeze(0))\n",
        "#   enc = cust_model.encoder(trans_comp(img).unsqueeze(0))\n",
        "#   enc = cust_model.fc_mu(enc).squeeze()\n",
        "#   img = enc.detach().numpy()\n",
        "#   img_paths.append(fl)\n",
        "#   img_emb_list.append(img)\n",
        "\n",
        "# data_tuples = list(zip(img_paths, img_emb_list))\n",
        "# df = pd.DataFrame(data_tuples, columns=['Image Path', 'Image Embeding'])\n",
        "# df.to_csv('/content/drive/MyDrive/geo_sim/' + 'image_embeddings.csv')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter: 0\n",
            "Iter: 100\n",
            "Iter: 200\n",
            "Iter: 300\n",
            "Iter: 400\n",
            "Iter: 500\n",
            "Iter: 600\n",
            "Iter: 700\n",
            "Iter: 800\n",
            "Iter: 900\n",
            "Iter: 1000\n",
            "Iter: 1100\n",
            "Iter: 1200\n",
            "Iter: 1300\n",
            "Iter: 1400\n",
            "Iter: 1500\n",
            "Iter: 1600\n",
            "Iter: 1700\n",
            "Iter: 1800\n",
            "Iter: 1900\n",
            "Iter: 2000\n",
            "Iter: 2100\n",
            "Iter: 2200\n",
            "Iter: 2300\n",
            "Iter: 2400\n",
            "Iter: 2500\n",
            "Iter: 2600\n",
            "Iter: 2700\n",
            "Iter: 2800\n",
            "Iter: 2900\n",
            "Iter: 3000\n",
            "Iter: 3100\n",
            "Iter: 3200\n",
            "Iter: 3300\n",
            "Iter: 3400\n",
            "Iter: 3500\n",
            "Iter: 3600\n",
            "Iter: 3700\n",
            "Iter: 3800\n",
            "Iter: 3900\n",
            "Iter: 4000\n",
            "Iter: 4100\n",
            "Iter: 4200\n",
            "Iter: 4300\n",
            "Iter: 4400\n",
            "Iter: 4500\n",
            "Iter: 4600\n",
            "Iter: 4700\n",
            "Iter: 4800\n",
            "Iter: 4900\n",
            "Iter: 5000\n",
            "Iter: 5100\n",
            "Iter: 5200\n",
            "Iter: 5300\n",
            "Iter: 5400\n",
            "Iter: 5500\n",
            "Iter: 5600\n",
            "Iter: 5700\n",
            "Iter: 5800\n",
            "Iter: 5900\n",
            "Iter: 6000\n",
            "Iter: 6100\n",
            "Iter: 6200\n",
            "Iter: 6300\n",
            "Iter: 6400\n",
            "Iter: 6500\n",
            "Iter: 6600\n",
            "Iter: 6700\n",
            "Iter: 6800\n",
            "Iter: 6900\n",
            "Iter: 7000\n",
            "Iter: 7100\n",
            "Iter: 7200\n",
            "Iter: 7300\n",
            "Iter: 7400\n",
            "Iter: 7500\n",
            "Iter: 7600\n",
            "Iter: 7700\n",
            "Iter: 7800\n",
            "Iter: 7900\n",
            "Iter: 8000\n",
            "Iter: 8100\n",
            "Iter: 8200\n",
            "Iter: 8300\n",
            "Iter: 8400\n",
            "Iter: 8500\n",
            "Iter: 8600\n",
            "Iter: 8700\n",
            "Iter: 8800\n",
            "Iter: 8900\n",
            "Iter: 9000\n",
            "Iter: 9100\n",
            "Iter: 9200\n",
            "Iter: 9300\n",
            "Iter: 9400\n",
            "Iter: 9500\n",
            "Iter: 9600\n",
            "Iter: 9700\n",
            "Iter: 9800\n",
            "Iter: 9900\n",
            "Iter: 10000\n",
            "Iter: 10100\n",
            "Iter: 10200\n",
            "Iter: 10300\n",
            "Iter: 10400\n",
            "Iter: 10500\n",
            "Iter: 10600\n",
            "Iter: 10700\n",
            "Iter: 10800\n",
            "Iter: 10900\n",
            "Iter: 11000\n",
            "Iter: 11100\n",
            "Iter: 11200\n",
            "Iter: 11300\n",
            "Iter: 11400\n",
            "Iter: 11500\n",
            "Iter: 11600\n",
            "Iter: 11700\n",
            "Iter: 11800\n",
            "Iter: 11900\n",
            "Iter: 12000\n",
            "Iter: 12100\n",
            "Iter: 12200\n",
            "Iter: 12300\n",
            "Iter: 12400\n",
            "Iter: 12500\n",
            "Iter: 12600\n",
            "Iter: 12700\n",
            "Iter: 12800\n",
            "Iter: 12900\n",
            "Iter: 13000\n",
            "Iter: 13100\n",
            "Iter: 13200\n",
            "Iter: 13300\n",
            "Iter: 13400\n",
            "Iter: 13500\n",
            "Iter: 13600\n",
            "Iter: 13700\n",
            "Iter: 13800\n",
            "Iter: 13900\n",
            "Iter: 14000\n",
            "Iter: 14100\n",
            "Iter: 14200\n",
            "Iter: 14300\n",
            "Iter: 14400\n",
            "Iter: 14500\n",
            "Iter: 14600\n",
            "Iter: 14700\n",
            "Iter: 14800\n",
            "Iter: 14900\n",
            "Iter: 15000\n",
            "Iter: 15100\n",
            "Iter: 15200\n",
            "Iter: 15300\n",
            "Iter: 15400\n",
            "Iter: 15500\n",
            "Iter: 15600\n",
            "Iter: 15700\n",
            "Iter: 15800\n",
            "Iter: 15900\n",
            "Iter: 16000\n",
            "Iter: 16100\n",
            "Iter: 16200\n",
            "Iter: 16300\n",
            "Iter: 16400\n",
            "Iter: 16500\n",
            "Iter: 16600\n",
            "Iter: 16700\n",
            "Iter: 16800\n",
            "Iter: 16900\n",
            "Iter: 17000\n",
            "Iter: 17100\n",
            "Iter: 17200\n",
            "Iter: 17300\n",
            "Iter: 17400\n",
            "Iter: 17500\n",
            "Iter: 17600\n",
            "Iter: 17700\n",
            "Iter: 17800\n",
            "Iter: 17900\n",
            "Iter: 18000\n",
            "Iter: 18100\n",
            "Iter: 18200\n",
            "Iter: 18300\n",
            "Iter: 18400\n",
            "Iter: 18500\n",
            "Iter: 18600\n",
            "Iter: 18700\n",
            "Iter: 18800\n",
            "Iter: 18900\n",
            "Iter: 19000\n",
            "Iter: 19100\n",
            "Iter: 19200\n",
            "Iter: 19300\n",
            "Iter: 19400\n",
            "Iter: 19500\n",
            "Iter: 19600\n",
            "Iter: 19700\n",
            "Iter: 19800\n",
            "Iter: 19900\n",
            "Iter: 20000\n",
            "Iter: 20100\n",
            "Iter: 20200\n",
            "Iter: 20300\n",
            "Iter: 20400\n",
            "Iter: 20500\n",
            "Iter: 20600\n",
            "Iter: 20700\n",
            "Iter: 20800\n",
            "Iter: 20900\n",
            "Iter: 21000\n",
            "Iter: 21100\n",
            "Iter: 21200\n",
            "Iter: 21300\n",
            "Iter: 21400\n",
            "Iter: 21500\n",
            "Iter: 21600\n",
            "Iter: 21700\n",
            "Iter: 21800\n",
            "Iter: 21900\n",
            "Iter: 22000\n",
            "Iter: 22100\n",
            "Iter: 22200\n",
            "Iter: 22300\n",
            "Iter: 22400\n",
            "Iter: 22500\n",
            "Iter: 22600\n",
            "Iter: 22700\n",
            "Iter: 22800\n",
            "Iter: 22900\n",
            "Iter: 23000\n",
            "Iter: 23100\n",
            "Iter: 23200\n",
            "Iter: 23300\n",
            "Iter: 23400\n",
            "Iter: 23500\n",
            "Iter: 23600\n",
            "Iter: 23700\n",
            "Iter: 23800\n",
            "Iter: 23900\n",
            "Iter: 24000\n",
            "Iter: 24100\n",
            "Iter: 24200\n",
            "Iter: 24300\n",
            "Iter: 24400\n",
            "Iter: 24500\n",
            "Iter: 24600\n",
            "Iter: 24700\n",
            "Iter: 24800\n",
            "Iter: 24900\n",
            "Iter: 25000\n",
            "Iter: 25100\n",
            "Iter: 25200\n",
            "Iter: 25300\n",
            "Iter: 25400\n",
            "Iter: 25500\n",
            "Iter: 25600\n",
            "Iter: 25700\n",
            "Iter: 25800\n",
            "Iter: 25900\n",
            "Iter: 26000\n",
            "Iter: 26100\n",
            "Iter: 26200\n",
            "Iter: 26300\n",
            "Iter: 26400\n",
            "Iter: 26500\n",
            "Iter: 26600\n",
            "Iter: 26700\n",
            "Iter: 26800\n",
            "Iter: 26900\n",
            "Iter: 27000\n",
            "Iter: 27100\n",
            "Iter: 27200\n",
            "Iter: 27300\n",
            "Iter: 27400\n",
            "Iter: 27500\n",
            "Iter: 27600\n",
            "Iter: 27700\n",
            "Iter: 27800\n",
            "Iter: 27900\n",
            "Iter: 28000\n",
            "Iter: 28100\n",
            "Iter: 28200\n",
            "Iter: 28300\n",
            "Iter: 28400\n",
            "Iter: 28500\n",
            "Iter: 28600\n",
            "Iter: 28700\n",
            "Iter: 28800\n",
            "Iter: 28900\n",
            "Iter: 29000\n",
            "Iter: 29100\n",
            "Iter: 29200\n",
            "Iter: 29300\n",
            "Iter: 29400\n",
            "Iter: 29500\n",
            "Iter: 29600\n",
            "Iter: 29700\n",
            "Iter: 29800\n",
            "Iter: 29900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4cASLP0AC6O"
      },
      "source": [
        "def conv(x):\n",
        "  tst = x.strip('[]').split()\n",
        "  tst2 = [float(t) for t in tst]\n",
        "  tst3 = np.array(tst2)\n",
        "  \n",
        "  return tst3"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yI6hFASngYZ"
      },
      "source": [
        "Then, we put the embeddings in a dataframe and save the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxP2ntXZoAy8"
      },
      "source": [
        "## Search Images\n",
        "\n",
        "When we're ready to perform the search, we simply load the precomputed embeddings, calculate the distance between each embedding and the embedding of the target image and return the closest images (the minimum distances)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afnkmVxkNV9c"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/geo_sim/' + 'image_embeddings.csv')\n",
        "from scipy.spatial.distance import cosine\n",
        "def search(model, df, img_path, n=5):\n",
        "  ''' Returns a list of nearest images for an input image\n",
        "\n",
        "  Inputs: model - the model to embed the image\n",
        "          df - a dataframe containing images previously embedded using the\n",
        "               embedding model. Should have columns = ['Image Path',\n",
        "               'Image Embedding']\n",
        "          img_path - the path to the test image\n",
        "          n [optional] - the number of nearest images to return\n",
        "\n",
        "  Returns - a dataframe containing information on the nearest images\n",
        "  '''\n",
        "  tmp_df = df.copy()\n",
        "  # print(tmp_df.head())\n",
        "  lst = []\n",
        "  for ii in range(len(tmp_df)):\n",
        "    tmp2 = conv(tmp_df.iloc[ii,2])\n",
        "    lst.append(tmp2)\n",
        "  tmp_df['Image Embeding'] = lst\n",
        "  # print(tmp_df.head())\n",
        "\n",
        "  img = Image.open(img_path)\n",
        "  img = np.asarray(img)\n",
        "  emb = cust_model.encoder(trans_comp(img).unsqueeze(0))\n",
        "  # print(emb.shape)\n",
        "  emb = cust_model.fc_mu(emb)\n",
        "  emb = emb.detach().numpy().squeeze()\n",
        "  # print(emb.shape)\n",
        "  func = lambda x: cosine(x, emb)\n",
        "  lst = tmp_df['Image Embeding']\n",
        "  lst2 = lst.apply(func,2)\n",
        "  # print(tmp_df.head)\n",
        "  tmp_df['Image Embeding'] = lst2\n",
        "  img_out = tmp_df.sort_values(by='Image Embeding')\n",
        "\n",
        "  return img_out"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzNBNXgqI9K9"
      },
      "source": [
        "out_img = search(cust_model, df, out[1000])"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouGhdigTKMGn"
      },
      "source": [
        "Now, we spot check some of the returned values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOsgbUQ0J2Wm",
        "outputId": "f3a7709f-dca2-496c-8b29-c8ac1e1980ae"
      },
      "source": [
        "print(out_img.iloc[0,1])\n",
        "print(out_img.iloc[1,1])\n",
        "print(out_img.iloc[2,1])\n",
        "print(out_img.iloc[3,1])\n",
        "print(out_img.iloc[4,1])"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/geo_sim/geological_similarity/quartzite/LSIXH.jpg\n",
            "/content/drive/MyDrive/geo_sim/geological_similarity/quartzite/6P5LU.jpg\n",
            "/content/drive/MyDrive/geo_sim/geological_similarity/quartzite/PLHJO.jpg\n",
            "/content/drive/MyDrive/geo_sim/geological_similarity/quartzite/0JF0L.jpg\n",
            "/content/drive/MyDrive/geo_sim/geological_similarity/quartzite/4G9KA.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZvjcQDbKTPO"
      },
      "source": [
        "Viola!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5i3pSprDk_Q"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEG4j-i3KRhu"
      },
      "source": [
        "# !pip install torch\n",
        "!pip install lightning-bolts[\"extra\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpg-sP4dDuUe"
      },
      "source": [
        "## Pip Freeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFqJRpYGDwRH",
        "outputId": "d52dcc13-26ae-4026-b569-310c2a4709ae"
      },
      "source": [
        "!pip freeze > /content/drive/MyDrive/requirements.txt\n",
        "!cat /content/drive/MyDrive/requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.266\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.30.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.0.1\n",
            "importlib-resources==5.1.3\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.4\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.15\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.0\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZVrbKTD3sg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}